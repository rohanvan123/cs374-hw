<h1 style="text-align: center;">Homework 7 - Problem 2</h1>
<p style="text-align: center;">Rohan Vanjani | vanjani3@illinois.edu</p>
<p style="text-align: center;">Rachel Samojedny | rcs6@illinois.edu</p>
<p style="text-align: center;"> Krish Desai | krishvd2@illinois.edu</p>

### 2 a.)

Our recursive algorithm can be defined as follows, where we have two functions. U(n) for if the edge connected to n is unmarked, which returns the number of distinct matchings for the subtree with root n. M(n) for if the edge connecting the parent of n to n is marked, which returns the number of distinct matchings for the subtree with root n.

$M(n)$ = 1 if n is a leaf, and $M(n) = \prod\_{\forall c \in children(n)} (U(c)) $ otherwise

$U(n)$ = 1 if n is a leaf, and $U(n) = \sum_{\forall c \in children(n)} (M(c) * \prod_{\forall m \in children(n) \wedge m \neq c } (U(m)))$ otherwise

Our main call at the top would be $U(root)$ because the root's parent is unmarked becasue it does not exist. To breifly explain the reucurrence, The function M(n), assuming the parent edge is marked, returns the power series of U(c) for each child c of n. The other function U(n), assuming the parent edge of n is umarked, returns the Sum for each child of n, the value of M(c) at that note times the power series of U(m) for neighbors of c not equal to itself. This is because if we chose to mark a child, we must consider all the posbillities of unmarked children, requiring multiplication instead of addition.

The base cases are when we are at a leaf node, in which M(n) and U(n) both return 1 becasue the only matching of that subtree is the empty set itself. Additionnally, we don't want to consider it zero because we are multiplying previous recusrive calls.

**Optimization**

To optimize this problem we can create two arrays of size T, the number of nodes in the tree. One representing the marked value at each node M[1...T] and unmarked U[1...T] respectively. We can match nodes with unique indices with some map-type data structure, where M[nodeToIdx(n)] represents the value in the array for node n. For the evulation order, we iterate from bottom to top (level-by-level), starting with the leaves (base cases) first, and the nodes above the leaves, which can be done with a postorder traversal. Then we can calculate our U[n] and M[n] values for a certain node n based on previously cached dependencies. If T represents the number of nodes in our tree the overall time complexity is $O(T^2)$ because our function U(n) computes a power series for each of the children of a specific node. Essentially, if this is computed throughout our traversal, it would end up being $O(T^2)$ or $O(n^2)$ if n is the total number of nodes in our tree. The space complexity is $O(n)$ because utilze two arrays of size n.

### 2 b.)

One thing to notice for a path specifically is that the number of matchings for a specific subtree is the number of matchings of its child's subtree plus the number of matchings of its grandchild's subtree. The reason why this is the case because for a specific node, we can consider it marked or unmarked. I fit is marked, then we consider everything after it's grandchildren (n - 2), and if unmarked we consider everything after its children (n - 1).

We can define our recurrence (which is really just the fibonnaci sequence) as follows, where i is the number of nodes in our path.

Matchings(1) = 0 if i is a leaf node (empty set)

Matchings(2) = 2 if i is the parent of a leaf node (empty set and single matching edge)

Matchings(i) = Matchings(i - 1) + Matchings(i - 2)

We can easily write the **optimized** version using two variable to track the number of matchings of the child and the number of matchings of the grandchild.

```
Matchings(n):
    child = 2
    grandchild = 1

    for i <- 3  to n:
        temp <- child
        child = child + grandchild
        grandchild temp

    return child
```

The function above is the optimized version of Fibonnaci, which runs in $O(n)$ time and $O(1)$ space, where n is the number of nodes in our path. this also works for any path, not even one starting at the root, all we really need is the size of that path.

The answer to the question if Matchings(500) can be represented as a 64-bit integer is No. this is because the value of Fib(500) is too large to be represented by a 64 bit integer.

### 2 c.)

To handle our solution for part a more carefully, we want to allow for larger values than 2^64. One solution is to store two different values, each 64-bit intergers. For example, if our number is 123456, the first integer would store 123 and the second 456 (similar to Karatsuba's algorithm and breaking splitting intgers). This allows us to store much larger integers and even multiply them in fashion similar to Karatsuba's algorithm. Overall, the time complexity would increase becasue of the differnet multiplications and combinations.

The runtime of our algorithm increases significantly, if we assume to use this modification, then we can consider worst case multiplications being $O(n^{log_2{3}})$, and if we are doing roughly around O(n^2) multiplications, this becomes $O(n^{2 + log_2{3}})$.

### 2 d.)

We can write the recurrence for our algorithm as follows:

let MaxWeight(v, k, flag) be a recursive function that returns that maximum weight matching subtree whose root is v with at most k edges available and a flag representing whether or not the edge in connecting v's parent to v is in our matching set.

Here are the cases:

```
MaxWeight(v, k, flag) = 0, if v is null or undefined

MaxWeight(v, k, flag) = 0, if v is a leaf node

MaxWeight(v, k, flag) = 0, if j is 0

MaxWeight(v, k, flag) = max{MaxWeight(v->left, k, true), MaxWeight(v->right, k, true)}, if flag = true

MaxWeight(v, k, flag) = max{MaxWeight(v->left, k, false), MaxWeight(v->right, k, false), MaxWeight(v->left, k-1, true), MaxWeight(v->left, k-1, true)}, if flag = true
```

Our main function would return:

```
return MaxWeight(r, k, false) // r is the root
```

To profide a brief explanation of the cases. The base cases are when v = null (this is 0), when v is a leaf, this is also 0, and when k = 0 (we have used up all our edges). For the general cases we consider when the node's parent edge (the node it shares with its parent) is included in our set. When this is true, flag is set to true, so we can really only consider the MaxWeight of the left and right children, where we don't take an edge and set our flag to flase. When our flag is false, then we have to take the max of four cases: taking the left/right edge and not taking the edge (we consider these other two cases becasue if k == 1, we may want to use a lower edge).

**Optimization**
This algorithm can be optimized by using a 3D cache:
MaxWeight[1 ... n, 0 ... k, 1 ... 2], which is still $O(n k)$, where n is the number of nodes in the true, assuming we can map nodes to unique indices with some data structure, and k is the number of edges we can use up to.

For our base cases in our table, we fill out all indices in our table for all indices where i is a leaf and k is 0 to 0. In our algorithm, we will handle null checks for left and right subtrees before array access. For the evulation order, we iterate from bottom to top (level-by-level), starting with the leaves (base cases) first, and the nodes above the leaves, which can be done with a postorder traversal. This ensures that dependencies/subproblems are evaluated first. Then we can calculate our MaxWeight[i, k, flag] values for a certain node i, k, and flag. If n represents the number of nodes in our tree and k the number of nodes we can use up to, the overall time complexity is $O(nk)$ because each subproblem is evauluated in constant time. Total space as mentioned above is $O(nk)$.

**General Case**

While this algorithm above handles the binary tree variant, the general case would be a modification that is more complicated. Instead of just evaluating the left and right, it involves evualuating the children at each node. This would further increase the time complexity because evaulting up to n - 1 subproblems is not constant. However, space complexity remains the same.
